---
title: "SEMINARIO"
author: "Mitzi Cubilla-Montilla"
date: "10 de junio de 2020"
output: 
  html_document:
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## <FONT COLOR="Red">Test No Paramétricos</FONT>
Los métodos no paramétricos se aplican a una amplia variedad de situaciones, puesto que no tienen los requisitos más estrictos de los métodos paramétricos correspondientes. En particular, los métodos no paramétricos **no requieren poblaciones distribuidas normalmente**.

## <FONT COLOR="Blue">Prueba chi cuadrado</FONT>

Es un método que permite valorar la independencia o no entre variables en una tabla de contingencia n x p.

Supuestos: 	La escala de medida es al menor nominal. Las muestras son independientes.

Hipótesis:

Ho: Existe independencia entre los factores o variables.

Ha: No existe independencia entre los factores o variables.

Ejemplo:

La siguiente tabla muestra la tabulación cruzada de la variable ingreso mensual (en filas) - dividido en tres categorías: menos de 2 mil; entre 2 y 4 mil y más de 4 mil- y la última marca de auto comprada (en columnas) - marcas: Ford, Toyota y Mitsubishi-.

Tabla de contingencia para estudiar la relación entre ingreso y marca de auto:

```{r}
tabla<-matrix(c(50, 200, 100, 200, 100, 25, 125, 350, 50), nrow=3) 
rownames(tabla)=c("Menos de 2000","2000 - 4000", "Mas de 4000")
colnames(tabla)=c("Ford","Toyota", "Mitsubishi")
print(tabla)
```

Ho: el ingreso mensual y la marca de auto son independientes.

Ha: la marca de auto depende del ingreso mensual


La función chisq.test aplicada sobre la tabla de contingencia devuelve el resultado de la prueba 

```{r}
chisq.test(tabla)
```

Con este resultado (p-value < 2.2e-16) se demuestra que la marca de auto depende del ingreso mensual.


## <FONT COLOR="Blue">Prueba de Fisher</FONT>

Esta prueba estadística permite analizar si dos variables dicotómicas son independientes o no, cuando la muestra a estudiar es demasiada pequeña y no se cumplen las condiciones necesarias para que la aplicación de la prueba chi cuadrado sea adecuada. Para la apliccaión de la prueba se requiere una tabla 2x2. 

Supuestos:Se permite que la variable esté medida al menos en una escala nominal; las muestras son aleatorias e independientes.

Hipótesis:

Ho: las dos variables son independientes.

Ho: las dos variables NO son independientes (están asociadas)

Ejemplo:

Tabla de contingencia para estudiar las diferencias en la prevalencia de obesidad entre sexos. 

```{r}
table<-matrix(c(1, 7, 4, 2),nrow=2) 
rownames(table)=c("mujeres","hombres")
colnames(table)=c("Obeso","No Obeso")
print(table)
```

Ho: el sexo y la obesidad son independientes

Ha: el sexo y la obesidad NO son independientes

Aplicación de la Prueba de Fisher sobre la tabla de contingencia

```{r}
fisher.test(table)
```

No existe evidencia estadística de asociación entre el sexo y el hecho de ser obeso o no en la población estudiada. 

## <FONT COLOR="Blue">Prueba de Wilcoxon</FONT>
La prueba de rangos con signos de Wilcoxon es una **prueba no paramétrica** para  muestras emparejadas. Es la alternativa a la prueba paramétrica *t Student* para **muestras pareadas**. Toma en cuenta, no sólo la posición de la observación (rangos), sino también la magnitud de las diferencias.

Supuestos: Esta prueba es aplicable a variables medibles por lo menos en una escala ordinal, los datos son pareados (muestras emparejadas).

Hipótesis:

Ho: Las distribuciones poblaciones son iguales. 

Ha: Hay diferencia entre las distribuciones poblacionales, la cual puede ser unidireccional o bidireccional.

Ejemplo:

Vamos a suponer que tenemos un grupo de 12 pacientes con artritis y se les suministran dos medicaciones distintos para aliviar los síntomas. Posteriormente a la aplicación de cada medicamento, se les pide que indiquen cuántas horas de alivio observaron con cada droga

*Paciente*|*Droga A*|*Droga B*|
|--------: |-------:  |-------:
|   1      |    2.0   |3.5     
|   2      |    3.6   |5.7     
    3      |    2.6   |2.9
    4      |    2.7   |2.4
    5      |    7.3   |9.9
    6      |    3.4   |3.3
    7      |   14.9   |16.7
    8      |    6.6   |6.0
    9      |    2.3   |3.8
    10     |    2.1   |4.0
    11     |    6.8   |9.1
    12     |    8.5   |20.9

```{r}
datos <- data.frame(Paciente = c( 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12),
  Droga.A = c( 2,  3.6,  2.6,  2.7,  7.3,  3.4,  14.9,  6.6,  2.3,  2.1,  6.8,  8.5),
  Droga.B = c( 3.5, 5.7,  2.9,  2.4,  9.9,  3.3,  16.7,  6,  3.8,  4,  9.1,  20.9))
wilcox.test(datos$Droga.A, datos$Droga.B, paired = TRUE)
```

Vemos que el valor p se encuentra debajo de un nivel de significanza (α=0.05)
con lo cual rechazamos Ho y concluimos que hay una diferencia estadísticamente significativa entre los dos medicamentos.

Observación: Cuando hay "empates", la función wilcox.test() no es capaz de calcular el p-value exacto por lo que devuelve una aproximación asumiendo que U se distribuye de forma ~ normal. En estos casos, o cuando los tamaños muestrales son mayores de 20, es recomendable emplear la función wilcox_test() del paquete coin.


## <FONT COLOR="Blue">Prueba de Mann-Whitney</FONT>
Contrasta la igualdad de dos distribuciones poblacionales, se basa en la suposición de que dos muestras aleatorias son independientemente. Es la contraparte de la prueba paramétrica t student para muestras independientes. 

Supuestos:
La escala de medida es al menos ordinal. Se tienen dos muestras aleatorias **independientes**, cada una extraída de una población diferente.


Hipótesis:

Ho: Las medias poblacionales son iguales.

Ha: Las poblaciones no tienen medias iguales.

*RStudio utiliza la función wilcox.test () que realiza un test de Mann–Whitney–Wilcoxon entre dos muestras, solo se debe indicar paired = False (esto permite utilizar la prueba en muestras independientes)*.


Ejemplo:

Una empresa aseguradora comparó la satisfacción de los clientes respecto a los seguros vendidos por dos corredores diferentes. La empresa entrevistó a los compradores de seguros de cada uno de los corredores durante el último mes, ocho para el corredor A y siete para el corredor B.  En cada caso se les pidió que señalaran el grado de satisfacción al tratar con el corredor, en una escala de 1 (baja) a 20 (alta).   

*Corredor A*|*Corredor B*|
|:--------: |:-------:  |
| 13     |    16  | 
| 18     |    10  | 
| 17     |    12  | 
| 20     |    15  | 
| 16     |    19  | 
| 20     |    17  | 
| 14     |    11  | 
| 15     |    

```{r}
A<-c(13, 18, 17, 20, 16, 20, 14, 15)
B<-c(16, 10, 12, 15, 19, 17, 11)
wilcox.test(A, B, alternative = "two.sided", mu = 0, paired = FALSE, conf.int = 0.95)
```

Por lo tanto, a un nivel de significancia de α=0.05, incluso a α=0.10, no hay evidencia suficiente para indicar que las calificaciones del nivel de satisfacción difieren de un corredor a otro.


## <FONT COLOR="Blue">Prueba de Kruskal-Wallis</FONT>

El test de Kruskal-Wallis es la alternativa **no paramétrica** al test *ANOVA de una vía* para datos no pareados (**muestras independientes**). Es una extensión del test de Mann-Whitney para más de dos grupos.Se trata por lo tanto de una prueba para contrastar la hipótesis de que k muestras han sido obtenidas de una misma población.

Supuestos: aleatoriedad en la extracción de las muestras y escala de medida al menos ordinal.

Ho: las k muestras provienen de la misma población.

Ha: alguna muestra proviene de una población con mediana diferente a las demás.

Ejemplo:

Cuatro grupos distintos de pacientes de fisioterapia se sometieron a diferentes regímenes de tratamiento. Al término de un periodo especificado, cada uno se sometió a una prueba con el fin de estimar la efectividad del tratamiento, obteniéndose los siguientes resultados:

Tratamiento 1: 64, 88, 72, 80, 79, 71

Tratamiento 2: 76, 70, 90, 80, 75, 82

Tratamiento 3: 58, 74, 66, 60, 82, 75

Tratamiento 3: 95, 90, 80, 87, 88, 85

¿Proporcionan estos datos evidencia suficiente que indique una diferencia entre tratamientos?

Ho: los 4 tratamientos provienen de la misma población, o bien, los tratamientos tienen la misma mediana

H1: alguna muestra proviene de una población con mediana diferente a las demás

```{r}
tratam1<-c(64, 88, 72, 80, 79, 71)
tratam2<-c(76, 70, 90, 80, 75, 82)
tratam3<-c(58, 74, 66, 60, 82, 75)
tratam4<-c(95, 90, 80, 87, 88, 85)
kruskal.test(list(tratam1, tratam2, tratam3, tratam4))
```

Los tratamientos tienen mediana diferentes.

## <FONT COLOR="Blue">Prueba de Friedman</FONT>

La prueba de Friedman permite contrastar si existen diferencias entre k  **muestras relacionadas**. Representa una alternativa **no paramétrica** para comparar el rendimiento de varios “tratamientos” de un diseño aleatorizado de *bloques en un experimento*.

Supuesto: las muestras tienen un orden natural, (aunque para darles sentido tienen que estar ordenados) y además son datos pareados.

Hipótesis:

Ho: No existen diferencias entre los grupos 

Ha: Hay diferencias entre los grupos

*Ejemplo*: 

Nueve estudiantes de medicina fueron evaluados en tres asignaturas distintas obteniendo las notas que se presentan a continuación.


Basica:     98, 95, 76, 95, 83, 99, 82, 75, 88

Fisiología: 95, 71, 80, 81, 77, 70, 80, 72, 81

Anatomía    77, 79, 81, 84, 80, 93, 87, 81, 83)

¿Existen diferencias en las notas obtenidas de acuerdo a la asignatura?

En RStudio, para aplicar la Prueba de Friedman, primero se crea una matriz con las observaciones de los individuos y las repeticiones (asignaturas)


```{r}
notas<-matrix(c(98, 95, 76, 95, 83, 99, 82, 75, 88,
                95, 71, 80, 81, 77, 70, 80, 72, 81,
                77, 79, 91, 84, 80, 93, 87, 81, 83),nrow=9,ncol=3,
              dimnames = list(1:9,c("Basica","Fisilogia","Anatomia")))
print(notas)
friedman.test(notas)
```
Se concluye que hay diferencias entre los grupos al nivel de significancia de 0.05, pero no al nivel de 0.01.

## <FONT COLOR="Blue">Otras pruebas</FONT>

mcnemar.test(antes,despues)  Test de McNemar: tabla de frecuencias 2 x 2 para recoger las respuestas de los mismos elementos antes y después de un tratamiento o experimento..

wilcox.test (datos, mu, alternative) Test de Wilcoxon para una muestra






